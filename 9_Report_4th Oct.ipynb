{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieN7JrTgyhOe",
        "outputId": "6713c572-891e-412c-c18a-54faea47e5aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting PyMuPDFb==1.24.10 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading PyMuPDF-1.24.10-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMuPDFb-1.24.10-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.10 PyMuPDFb-1.24.10\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLCNFxVXyupQ",
        "outputId": "978396ef-543e-4c7b-f6c6-d78bf67de060"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + ' '\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "ZpGM40bdyr3_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def identify_ayurvedic_terms(text):\n",
        "    pattern = r'\\b[a-zA-Z]{3,}\\b'  # Match words with at least three letters\n",
        "    matches = re.findall(pattern, text)\n",
        "\n",
        "    filtered_terms = set(word.lower() for word in matches if word.lower() not in stopwords.words('english'))\n",
        "\n",
        "    return filtered_terms\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR_4MSrByxSC",
        "outputId": "82ce94f9-a9f9-46c9-cc9b-c2e892589ea1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def define_relationships(sentences, ayurvedic_terms):\n",
        "    relationships = defaultdict(set)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        found_terms = set(term for term in ayurvedic_terms if term in sentence.lower())\n",
        "        for term1 in found_terms:\n",
        "            for term2 in found_terms:\n",
        "                if term1 != term2:\n",
        "                    relationships[term1].add(term2)\n",
        "\n",
        "    return relationships\n"
      ],
      "metadata": {
        "id": "PQ2_QXajy0lJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPIM4NWhy8FV",
        "outputId": "311174ea-faae-4378-d7ca-66be9fccb070"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdflib\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting isodate<0.7.0,>=0.6.0 (from rdflib)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib) (3.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib) (1.16.0)\n",
            "Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: isodate, rdflib\n",
            "Successfully installed isodate-0.6.1 rdflib-7.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdflib import Graph, URIRef, Literal, Namespace\n",
        "\n",
        "def create_knowledge_graph(relationships):\n",
        "    g = Graph()\n",
        "    ayurveda_ns = Namespace(\"http://example.org/ayurveda/\")\n",
        "\n",
        "    for term, related_terms in relationships.items():\n",
        "        term_uri = URIRef(ayurveda_ns[term])\n",
        "        g.add((term_uri, URIRef(ayurveda_ns['type']), Literal('AyurvedicTerm')))\n",
        "\n",
        "        for related_term in related_terms:\n",
        "            related_uri = URIRef(ayurveda_ns[related_term])\n",
        "            g.add((term_uri, URIRef(ayurveda_ns['relatedTo']), related_uri))\n",
        "\n",
        "    return g\n"
      ],
      "metadata": {
        "id": "AgJRUEDzy4PL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_knowledge_graph(graph, filename):\n",
        "    graph.serialize(destination=filename, format='turtle')  # You can change format as needed\n"
      ],
      "metadata": {
        "id": "KQPtZN76zBst"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def main(pdf_path, graph_filename):\n",
        "    # Extract text from the PDF\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Identify Ayurvedic terms using regex\n",
        "    ayurvedic_terms = identify_ayurvedic_terms(text)\n",
        "\n",
        "    # Split text into sentences for relationship extraction\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "    # Define relationships between terms\n",
        "    relationships = define_relationships(sentences, ayurvedic_terms)\n",
        "\n",
        "    # Create the knowledge graph\n",
        "    knowledge_graph = create_knowledge_graph(relationships)\n",
        "\n",
        "    # Save the knowledge graph to a file\n",
        "    save_knowledge_graph(knowledge_graph, graph_filename)\n",
        "\n",
        "    print(\"Knowledge graph created and saved to\", graph_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgGOA3jXzf82",
        "outputId": "c83ddc49-3ea8-4081-e543-86bb291f9d2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = 'Disease explanation in charaka samhita made easy - Ebook-7-42.pdf'  # Replace with your PDF file path\n",
        "graph_filename = 'ayurvedic_terms_knowledge_graph.ttl'  # Output graph file\n",
        "main(pdf_path, graph_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajA_9i7xzPIp",
        "outputId": "ed022a5f-2af2-48fd-9cea-e8a0cdf73203"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Knowledge graph created and saved to ayurvedic_terms_knowledge_graph.ttl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCaT27QuzVqJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}